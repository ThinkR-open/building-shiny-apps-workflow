# Optimizing Shiny Code

## Optimizing R code 

// TODO 

## Caching elements

### What's caching? 

Caching is the process of storing resources intensive results so that when they are needed again, your programm can reuse the result again without having to redo it another time.

Let's imagine that you know that you'll need to use a phone number many time in the day, and for the purpose of this thought experiment you're completly unable to remember it^[
Human memory is a form of caching
].
What are you going to do? 
There are two solutions here: either every time you need it you look in the phone book or in your phone contact list, making it so that it takes a couple of seconds every time, or you use a post-it that you put on your computer screen with the number of it, so that you have direct access to it when you need it. 
It takes a couple of seconds the first time you look for the number, but it's almost instantaneous the next times you need it.

This is what caching do: keep the result of computation so when they are needed in the very same context, they are quickly accessible.
The downside being that you only have limited space on your screen: when your screen is covered by sticky notes, you can't store any more notes^[
In that case, you can either hide pre-existing sticky notes, or buy a bigger screen. 
But we are not here to talk about cache management theory. 
// TODO REFERENCE TO "Algorithm to live by"
]. 

In the context of an interactive application in a framework like Shiny, it makes much sense to cache data structures: users tend to repeat what they do, or go back and forth between parameters. 
For example, if you have a graph that take 2 seconds to render (which is quite common in Shiny), you don't want these 2 seconds to be repeated over and over again when users switch from one parameter to another and back to the first, as the two graphs will be the same for the same parameter. 
Same goes for queries to a database: if a query is done with the same parameters, and you know that they will return the same result, there is no need to ask the database—ask the cache to retrieve the data.

### Using caching in R 

At least two packages in R implement caching of functions (also called memoization): `{memoize}`, and `{memoise}`. 
They both more or less work the same way: you'll call a memoization function on another function, and cache is created for this function. 
Then everytime you call this function again with the same parameters, the cache is returned instead of computing again. 
Here is a simple example with `{memoise}`:

```{r optimizing-shiny-code-1}
library(memoise)
library(tictoc)
fct <- function(sleep = 1){
  Sys.sleep(sleep)
  return(Sys.time())
}
mfct <- memoise(fct)
tic()
mfct(2)
toc()
tic()
mfct(2)
toc()
```

Let's try with another example that might look more like what we can find in a Shiny App: connecting to a database 

```{r optimizing-shiny-code-2}
con <- DBI::dbConnect(
  RSQLite::SQLite(), 
  dbname = ":memory:"
)
DBI::dbWriteTable(
  con, 
  "diams", 
  dplyr::bind_rows(
    purrr::rerun(10, ggplot2::diamonds)
  )
)

fct_sql <- function(SQL, con){
  DBI::dbGetQuery(
    con, SQL
  ) 
}
mfct <- memoise(fct_sql)
tic()
res_a <- mfct("SELECT * FROM diams WHERE cut = 'Ideal'", con)
toc()
tic()
res_b <- mfct("SELECT * FROM diams WHERE cut = 'Ideal'", con)
toc()
all.equal(res_a, res_b)
tic()
res_c <- mfct("SELECT * FROM diams WHERE cut = 'Good'", con)
toc()
setequal(res_a, res_c)
```

Note that you can change where the cache is stored by `{memoise}`. Here, we'll save it in the temp directory, but don't do this in production.

```{r optimizing-shiny-code-1-bis}
tpd <- fs::path(tempdir(), paste(sample(letters, 10), collapse = ""))
```

```{r optimizing-shiny-code-2-bis, include = FALSE, error = TRUE}
try(fs::dir_delete(tpd))
```

```{r optimizing-shiny-code-3}
tpd <- fs::dir_create(tpd)
dfs <- cache_filesystem(tpd)
mfct <- memoise(fct_sql, cache = dfs)
res_a <- mfct("SELECT * FROM diams WHERE cut = 'Ideal'", con)
res_b <- mfct("SELECT * FROM diams WHERE cut = 'Good'", con)
fs::dir_ls(tpd)
```

As you can see, I now have two cache objects inside the directory I've specified as a `cache_filesystem`.

### Caching Shiny

At the time of writing this page (January 2020), `{shiny}` has one caching function: `renderCachedPlot()`. 
This function behaves more or less like the `renderPlot()` function, except that it is tailored for caching. 
The extra arguments you'll find are `cacheKeyExpr` and `sizePolicy`: the former is the list of inputs and values that allow to cache the plot—conceptually, every time these values and inputs are the same, they produce the same graph. 
`sizePolicy` is a function that returns a `width` and an `height`, and which are used to round the plot dimension in pixels, so that not every pixel combination are generated in the cache.

The good news is that converting existing `renderPlot()` functions to `renderCachedPlot()` is pretty straightforward in most cases: take your current `renderPlot()`, and add the cache keys^[
In some cases you'll have to configure the size policy, but in most cases the default value work just well. 
].

Here is an example: 

```{r optimizing-shiny-code-4, eval=FALSE}
library(shiny)
ui <- function(request){
  tagList(
    selectInput("tbl", "Table", c("iris", "mtcars", "airquality")),
    plotOutput("plot")
  )
}

server <- function(
  input, 
  output, 
  session
){
  
  output$plot <- renderCachedPlot({
    plot(
      get(input$tbl)
    )
  }, cacheKeyExpr = {
    input$tbl
  })
  
}

shinyApp(ui, server)
```

If you try this app, the first rendering of the three plots will take a little bit of time, but every subsequent rendering of the plot is almost instantaneous. 

And if we apply what we've just sen with `{memoise}`:

```{r optimizing-shiny-code-5, eval=FALSE}
con <- DBI::dbConnect(
  RSQLite::SQLite(), 
  dbname = ":memory:"
)
DBI::dbWriteTable(
  con, 
  "diams", 
  dplyr::bind_rows(
    purrr::rerun(100, ggplot2::diamonds)
  )
)

fct_sql <- function(cut, con){
  # NEVER EVER SPRINTF AN SQL CODE LIKE THAT
  # IT'S SENSITIVE TO SQL INJECTIONS, WE'RE
  # DOING IT FOR THE EXAMPLE
  DBI::dbGetQuery(
    con, sprintf(
      "SELECT * FROM diams WHERE cut = '%s'", 
      cut
    )
  )  %>% head()
}
db <- cache_filesystem("cache/")
fct_sql <- memoise(fct_sql, cache = db)
ui <- function(request){
  tagList(
    selectInput("cut", "cut", unique(ggplot2::diamonds$cut)),
    tableOutput("tbl")
  )
}

server <- function(
  input, 
  output, 
  session
){
  
  output$tbl <- renderTable({
    fct_sql(input$cut, con)
  })
  
}

shinyApp(ui, server)
```

You'll see that the first time you run this piece of code, it will take a couple of seconds to render the table for a new `input$cut` value.
But if you re-select this input a second time, the output will show instantaneously.

Caching is a nice way to make your app faster: even more if you expect your output to be stable over time: if the plot created by a series of inputs stays the same all along your app lifecycle, it's worth thinking about implementing an on-disk caching.
If your application needs "fresh" data every time it is used, for example because data in the SQL database are updated every hour, cache won't help you here, on the contrary: the same inputs on the function will render different output. 

Note thought that, just like our computer screen from before, you don't have unlimited space when it come to storing cache:storing a large amount of cache will take space on your disk. 

For example, from our stored cache from before:

```{r optimizing-shiny-code-6}
fs::dir_info(tpd)[, "size"]
```

Managing cache at a system level is out of scope for this book, but note that the most commonly accepted rule for deleting cache is called __LRU__, for __Least Recently Used__. 
The underlying principle of this approach is that users tend to need what they have needed recently: hence the more a piece of data has been used recently, the more likely it is that it will be needed soon. 

And this can be seen with:

```{r optimizing-shiny-code-7, echo = FALSE}
Sys.sleep(5)
res_a <- mfct("SELECT * FROM diams WHERE cut = 'Ideal'", con)
```

```{r optimizing-shiny-code-8}
fs::dir_info(tpd)[, "access_time"]
```

## Asynchronous in Shiny 

One of the drawbacks of Shiny is that as it's running on top of R, it's single threaded: meaning that each computation is run in sequence, one after the other. 
Well, at least natively, as methods have emerged to run pieces of code in parallel. 

### How to

To launch code blocks in parallel, we will use a combination of two packages, `{future}` and `{promises}`, and a `reactiveVal()`. 
`{future}` is an R package which main purporse is to allow users to send code to be run elsewhere, i.e in another session, thread, or even in another machine. 
`{promises}`, on the other hand, is a package providing structure for handling asynchronous programming in R.

#### Asynchronous for Cross-sessions Availability

The first type of asynchronous programming in Shiny is the one that allow non-blocking programming in a cross-session context. 
In other words, it's a programming technic which is useful in the context of running one Shiny session which is accessed by multiple users. 
Natively, in Shiny, if user1 comes and launches a 15 second computation, then user2 has to wait for this computation to finish, before launching their own 15 second computation, and user 3 has to wait the 15 seconds of user1 plus the 15 seconds for useré, etc. 

With `{future}` and `{promises}`, each long computation is sent to be run somewhere else, so when user1 launches their 15 second computation, they are not blocking the R process for user2 and user3. 

How does it work^[
We're providing a short introduction with key concepts, but for a more thourough introduction, please refer to the [online documentation](https://rstudio.github.io/promises/index.html)
]? 
`{promises}` comes with two operators which will be useful in our case, `%...>%` and `%...!%`: the first being "what happens when the `future()` is solved?" (i.e. when the computation from the `future()` is completed), and the second is "what happens if the `future()` fails?" (i.e. what to do when the `future()` returns an error). 
Here is an example of using this skeleton: 

```{r}
library(future)
library(promises)
plan(multisession) # We're opening several R session (future specific)
future({
  Sys.sleep(3)
  return(rnorm(5))
}) %...>% (
  function(result){
    print(result)
  }
) %...!% (
  function(error){
    stop(error)
  }
)
```

If you run this in your console, you will see that you have access to the R console directly after launching the code. 
And a couple of seconds later (a little bit more than 3), the result of the `rnorm(5)` will be printed to the console. 

Note that you can also one line function with `.` as a parameter, instead of building the full anonymous function (we will use this notation in the rest of the chapter): 

```{r}
library(future)
library(promises)
plan(multisession) # We're opening several R session (future specific)
future({
  Sys.sleep(3)
  return(rnorm(5))
}) %...>% 
  print(.) %...!% 
  stop(.)
```

Let's port this to Shiny:

```{r}
library(shiny)
ui <- function(request){
  tagList(
    verbatimTextOutput("pr")
  )
}

server <- function(
  input, 
  output, 
  session
){
  output$pr <- renderPrint({
    future({
      Sys.sleep(3)
      return(rnorm(5))
    }) %...>% 
      print(.) %...!% 
      stop(.)
  })
}

shinyApp(ui, server)
```

If you have run this, that does not seem like a revolution: but trust us, the `Sys.sleep()` is not blocking as it allows other users to launch the same computation at the same moment.

#### Inner-session Asynchronousity

In the previous section we have implemented cross-session asynchronousity, meaning that the code is non-blocking but for when two or more users access the same app. 
But the code is still blocking at an inner-session level. 
Let's have a look at this code:

```{r}
library(shiny)
ui <- function(request){
  tagList(
    verbatimTextOutput("pr"), 
    plotOutput("plot")
  )
}

server <- function(
  input, 
  output, 
  session
){
  output$pr <- renderPrint({
    future({
      Sys.sleep(3)
      return(rnorm(5))
    }) %...>% 
      print(.) %...!% 
      stop(.)
  })
  
  output$plot <- renderPlot({
    plot(iris)
  })
}

shinyApp(ui, server)
```

Here, you would expect the plot to be avaiable before the `rnorm()`, but it's not: `{promises}` is still blocking at an inner-session level, so elements are still rendered sequentially. 
To bypass that, we will use a `reactiveVal()` structure. 

```{r}
library(shiny)
library(promises)
library(future)
plan(multisession)


ui <- function(request){
  tagList(
    verbatimTextOutput("pr"), 
    plotOutput("plot")
  )
}

server <- function(
  input, 
  output, 
  session
) {
  
  rv <- reactiveVal()
  
  rv(NULL)
  
  future({
    Sys.sleep(5)
    rnorm(5)
  }) %...>%
    rv() %...!%
    (function(e){
      rv(NULL)
      warning(e)
    })
  
  output$pr <- renderPrint({
    req(rv())
    rv()
  })
  
  output$plot <- renderPlot({
    plot(iris)
  })
}

shinyApp(ui, server)
```

Let's detail this step by step: 

+ `rv <- reactiveVal()`

+ `rv(NULL)`

+ `%...>% rv() %...!%`

+ `%...!% (function(e){ rv(NULL) ; warning(e) })`